{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Black-Scholes model\n",
    "\n",
    "This is a simple example of learning the valuation function of a plain-vanilla put option in 5 dimensions:\n",
    "* Spot price\n",
    "* Time to maturity\n",
    "* Volatility\n",
    "* Discount rate\n",
    "* Dividend rate\n",
    "\n",
    "Due to the obvious scalability of the model, the Strike price is fixed at $1.\n",
    "Using this code, the user should be able to achieve the average accuracy of about 0.1 cent. \n",
    "\n",
    "The network architecture is a fully connected MLP with four hidden layers with 100 ReLU neurons each.\n",
    "\n",
    "The code will detect and run on GPU (if available) or CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Black Scholes put model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ds(K, S, T, vol, r, q):\n",
    "    vol_T = vol * np.sqrt(T)\n",
    "    d1 = (np.log(S/K) + (r - q + 0.5 * vol * vol) * T) / vol_T\n",
    "    d2 = d1 - vol_T\n",
    "    return d1, d2\n",
    "\n",
    "def put(K, S, T, vol, r, q):\n",
    "\n",
    "    disc = np.exp(-r * T)\n",
    "    pv_K = K * disc\n",
    "    spot_after_div = S * np.exp(-q * T)\n",
    "\n",
    "    d1, d2 = ds(K, S, T, vol, r, q)\n",
    "    v = norm.cdf(-d2) * pv_K - norm.cdf(-d1) * spot_after_div\n",
    "    return v * 100.\n",
    "\n",
    "v_put = np.vectorize(put)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate train, test, and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix seeds for reproducibility\n",
    "seed = 314\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training domain\n",
    "domain = {\n",
    "    \"spot\": (0.5, 2),\n",
    "    \"time\": (0, 3.0),\n",
    "    \"sigma\": (0.1, 0.5),\n",
    "    \"rate\": (-0.01, 0.03),\n",
    "    \"div\": (0, 0.02)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100000          # Total number of samples\n",
    "pct_test = 0.2              # Portion for test set\n",
    "pct_validation = 0.1        # Portion for validation set\n",
    "\n",
    "samples = np.zeros(shape=(len(domain.keys()), n_samples))\n",
    "for i, r in enumerate(domain.values()):\n",
    "    samples[i] = np.random.uniform(r[0], r[1], n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Calculate BSM values\n",
    "values = v_put(K=1, S=samples[0], T=samples[1], vol=samples[2], r=samples[3], q=samples[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_t = torch.from_numpy(samples.T).float()\n",
    "values_t = torch.from_numpy(values).float().unsqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define DNN architecture and learning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_layers, n_output):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.linears = torch.nn.ModuleList([torch.nn.Linear(n_feature, n_hidden)])\n",
    "        self.linears.extend([torch.nn.Linear(n_hidden, n_hidden) for i in range(1, n_layers)])\n",
    "        self.linears.append(torch.nn.Linear(n_hidden, n_output))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for lin in self.linears[:-1]:\n",
    "            x = F.relu(lin(x))       # Activation function for hidden layer\n",
    "        x = self.linears[-1](x)             # Apply last layer without activation\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_net(net: Net, n_epochs: int, x: torch.tensor, y: torch.tensor,\n",
    "            pct_test: int, pct_validation: int, device: str='cpu'):\n",
    "\n",
    "    n = y.size()[0]\n",
    "    n_train = int(np.round(n * (1 - pct_test - pct_validation)))\n",
    "    n_test = int(np.round(n * pct_test))\n",
    "    \n",
    "    x_train = x[:n_train]\n",
    "    x_test = x[n_train:(n_train + n_test)]\n",
    "    y_train = y[:n_train]\n",
    "    y_test = y[n_train:(n_train + n_test)]\n",
    "    \n",
    "    net.to(device)\n",
    "    x_ = x_train.to(device)\n",
    "    y_ = y_train.to(device)\n",
    "\n",
    "    x_test_ = x_test.to(device)\n",
    "    y_test_ = y_test.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "    loss_func = torch.nn.MSELoss()\n",
    "   \n",
    "    l = 123.45\n",
    "    best_l = 1e-3\n",
    "    checkpoint = {}\n",
    "\n",
    "    \n",
    "    for e in range(n_epochs):\n",
    "        prediction = net(x_)\n",
    "        loss = loss_func(prediction, y_)\n",
    "\n",
    "        prediction_test = net(x_test_)\n",
    "        loss_test = loss_func(prediction_test, y_test_)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        l = loss_test.data.cpu().numpy()\n",
    "        if l.item() < best_l:\n",
    "            best_l = l.item()\n",
    "            checkpoint = {\n",
    "                \"n_hidden\": net.n_hidden,\n",
    "                \"n_layers\": net.n_layers,\n",
    "                \"model_state_dict\": net.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            }\n",
    "        if (e + 1) % 100 == 0:\n",
    "            print(f\"\\tEpoch: {e+1}\\tL2 Loss = {loss.data.cpu().numpy()}\")\n",
    "\n",
    "    return best_l, checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "    print(f\"GPU detected. Running on {device}\")\n",
    "else:\n",
    "    print(\"No GPU detected. Running on CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define network architecture and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(n_feature=5, n_hidden=100, n_layers=4, n_output=1)  # define the network\n",
    "print(net)  # net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 6000\n",
    "ls, checkpoint = fit_net(net, n_epochs, samples_t, values_t, pct_test, pct_validation, device)\n",
    "print(f\"Best loss ={ls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make copy of network from checkpoint and validate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(n_feature=5,\n",
    "            n_hidden=checkpoint[\"n_hidden\"],\n",
    "            n_layers=checkpoint[\"n_layers\"],\n",
    "            n_output=1)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = values_t.size()[0]\n",
    "ind_validation = n_train = int(np.round(n * (1 - pct_validation)))\n",
    "samples_validation = samples_t[ind_validation:].to(device)\n",
    "values_validation = values_t[ind_validation:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_nn = model(samples_validation).flatten().data.cpu().numpy()\n",
    "error = v_nn - values_validation.flatten().data.cpu().numpy()\n",
    "mean_err = np.mean(error)\n",
    "std_error = np.std(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(error, bins=50)\n",
    "plt.title(\"Error histogram for validation set\")\n",
    "print(f\"Mean error = {mean_err:.4f}, StDev = {std_error:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mll_gpu",
   "language": "python",
   "name": "mll_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
